# The Ethics & Integrity Question

## The Conversation You Must Have

If you implement any of the ideas in this booklet, you will have this conversation—with students, with colleagues, possibly with administrators:

**"Aren't you just teaching students to cheat?"**

This chapter gives you the framework, language, and evidence to respond confidently. More importantly, it helps you position AI integration not as an academic integrity *problem*, but as an academic integrity *opportunity*—a chance to teach professional ethics and responsible technology use.

---

## Reframing the Question

The traditional framing:
> "How do we prevent students from using AI inappropriately?"

The professional framing:
> "How do we teach students to use AI responsibly in their professional careers?"

**The shift matters.**

The first framing treats AI as a threat to be controlled. The second treats AI literacy as a learning objective to be developed.

As a business educator across any discipline, you're not preparing students for a world without AI. You're preparing them for a world where AI tools will be discipline-specific but ubiquitous. Your graduates will use these tools:

::: {.panel-tabset}

## HR
- Screen resumes and identify candidates
- Draft employment contracts and policies
- Analyse workforce data and predict turnover
- Generate interview questions and assessment criteria
- Summarize complex legislation and case law

## Finance
- Analyse financial statements and identify anomalies
- Generate investment recommendations
- Perform risk assessments and stress testing
- Summarize regulatory requirements and tax implications
- Forecast financial performance

## Supply Chain
- Forecast demand and optimize inventory
- Identify supplier risks and opportunities
- Optimize logistics networks and routes
- Analyse supply chain resilience
- Generate sourcing recommendations

## Marketing
- Analyse customer data and segment audiences
- Generate campaign strategies and content
- Predict customer behaviour and preferences
- Optimize pricing and promotional strategies
- Analyse competitive positioning

## Information Systems
- Generate code and identify bugs
- Design system architectures
- Assess technology risks and security
- Create project plans and estimates
- Analyse requirements and specifications

:::

Your graduates will use these tools. The question is: **Will they use them competently and ethically, or incompetently and recklessly?**

That's what this chapter is about.

---

## The Three-Part Framework for Ethical AI Use

This framework works for talking to students, colleagues, and administrators. It has three components:

### 1. Transparency (Not Prohibition)

**The principle:** Make AI use explicit, expected, and assessable rather than hidden and policed.

**In practice:**
- Tell students exactly when and how they can use AI
- Provide the prompts and tools yourself
- Assess their *use* of AI, not their *avoidance* of AI
- Reward students who identify AI's errors and limitations

**Why this builds integrity:**
When AI use is transparent, students learn to use it openly and responsibly. When it's prohibited, students use it secretly and don't develop critical oversight skills.

### 2. Critical Oversight (Not Blind Reliance)

**The principle:** Teach students that AI is a tool requiring human judgment, not an authority to be trusted.

**In practice:**
- Design assignments where students must critique or override AI outputs
- Require students to identify what AI gets wrong
- Grade students on their ability to improve on AI suggestions
- Show examples of AI failures (bias, errors, oversimplification)

**Why this builds integrity:**
Students learn that using AI thoughtfully is harder than avoiding it. They develop the professional habit of verification and critical thinking.

### 3. Professional Relevance (Not Academic Abstraction)

**The principle:** Connect AI use in coursework to AI use in professional practice.

**In practice:**
- Frame assignments as professional scenarios: "You're the HR manager using AI to draft a policy..."
- Discuss workplace AI ethics: "What happens if your AI resume screening tool discriminates?"
- Teach governance: "Who is accountable when AI-assisted decisions go wrong?"
- Include AI literacy as a stated learning objective in your unit outline

**Why this builds integrity:**
When students see AI use as professional skill development rather than academic shortcut, they engage differently. They're not "cheating the system"—they're practicing for their careers.

---

## Student-Facing Language: Setting Expectations

You need clear, direct communication about AI use. Here's a model you can adapt:

### Example: Unit Outline AI Policy Statement

```
ARTIFICIAL INTELLIGENCE USE IN THIS UNIT

In professional practice across all business disciplines, you will use AI tools
to support decision-making, analysis, and communication. This unit teaches you to
use AI responsibly and critically.

WHEN AI USE IS EXPECTED:
- Assignment 2 (Conversation Simulation / Scenario Analysis): You will interact
  with AI-generated scenarios or personas and demonstrate your professional skills
- Assignment 3 (Self-Assessment): You will use the provided AI critique prompt
  to assess your draft before submission
- [Any other assignments where AI engagement is part of learning objectives]

WHEN AI USE IS PERMITTED:
- Brainstorming ideas and approaches
- Generating practice questions and scenarios for exam preparation
- Checking grammar and clarity in written work
- Exploring concepts you don't fully understand yet
- Researching and understanding professional standards and frameworks

WHEN AI USE IS NOT PERMITTED:
- Final exam (closed book, no technology unless specified)
- Any assignment where instructions explicitly state "no AI tools"
- Any assessment explicitly designed to test recall or your unaided thinking

WHAT YOU MUST DO WHEN USING AI:
- Use it as a tool that supports YOUR thinking, not replaces it
- Critically evaluate AI outputs—don't assume they're correct
- Be able to explain and justify any AI-assisted work in your own words
- Acknowledge AI use where required (e.g., "I used Claude to generate initial
  analysis, which I then critically reviewed and revised based on...")

ACADEMIC INTEGRITY EXPECTATIONS:
Using AI inappropriately (e.g., submitting AI-generated work as your own without
critical engagement) is academic misconduct, just like plagiarism.

If you're ever unsure whether your AI use is appropriate, ask before submitting.
I'm here to help you learn to use these tools well and ethically.
```

### Example: First-Day Class Discussion

**What to say:**

> "Let's talk about AI. Some of you are probably already using ChatGPT or similar tools. Some of you are worried that using AI is cheating. Some of you are wondering if I'm going to try to detect and punish AI use.
>
> Here's my position: **AI tools exist, and you'll use them in your professional careers. My job is to teach you to use them wisely and ethically.**
>
> In this unit, we'll use AI openly in some assignments. You'll learn when AI is helpful, when it's risky, and when human judgment must override AI recommendations. That's a professional skill you'll need.
>
> I'm not interested in playing 'gotcha' with AI detection software. I'm interested in whether you can think critically, justify your decisions, and demonstrate competent professional practice. If you can do that with AI assistance, great. If you use AI to avoid thinking, I'll know—because your work won't demonstrate understanding.
>
> Questions or concerns about this approach?"

**Why this works:**
- Sets a clear, positive tone
- Positions you as a guide, not a cop
- Acknowledges student anxiety
- Makes professional relevance explicit
- Invites dialogue

---

## Designing "Integrity-Resistant" Assignments

Some assignments are easier to misuse with AI than others. Here's how to design assessments that are inherently resistant to misuse:

### Principle 1: Assess Process, Not Just Product

**Vulnerable design:** "Write a 1500-word essay analysing a workplace conflict."
- Student can paste this into AI and submit the output

**Integrity-resistant design:** "Conduct a simulated investigation interview (submit transcript), then audit your own process against procedural fairness criteria."
- Student must engage in real-time conversation (can't be pre-written)
- Assessment focuses on methodology visible in transcript
- Self-audit requires metacognitive engagement

### Principle 2: Require Evidence of Thinking

**Vulnerable design:** "Recommend a solution to this [discipline] problem."
- AI can generate a plausible recommendation

**Integrity-resistant design:** "AI generated three solutions to this problem [provide them]. Critique each option, identify which one is best and why, and explain what the AI got wrong."
- Student must think beyond what AI provided
- Requires critical evaluation, not just generation
- Makes AI outputs the starting point, not the end point

**Examples by discipline:**
- HR: "Critique three AI-generated performance management approaches"
- Finance: "Critique three AI-generated investment recommendations"
- Supply Chain: "Critique three AI-generated supplier selection strategies"
- Marketing: "Critique three AI-generated campaign strategies"

### Principle 3: Make Personal Context Essential

**Vulnerable design:** "Analyse the pros and cons of [generic professional concept]."
- Generic question AI can answer generally

**Integrity-resistant design:** "Based on your earlier [simulation/analysis/project], analyse how [concept] would address the specific situation while meeting [organisational/business requirement]."
- Requires integration of previous personalised work
- Context is unique to each student
- Generic AI response won't fit

**Examples by discipline:**
- HR: "Based on your PIP simulation with Jamie, analyse flexible work approaches"
- Finance: "Based on your company analysis, evaluate investment timing strategies"
- Supply Chain: "Based on your supplier evaluation, analyse relationship strategies"
- Marketing: "Based on your segment analysis, evaluate messaging approaches"

### Principle 4: Assess Revision and Iteration

**Vulnerable design:** Submit final work only
- No visibility into how it was created

**Integrity-resistant design:** Submit first draft, AI feedback received, revised draft, and reflection on changes made
- Process is visible and assessable
- Shows learning trajectory
- Difficult to fake iterative improvement

### Principle 5: Require Justification of Choices

**Vulnerable design:** "Create a recruitment interview guide."
- AI can generate a complete guide

**Integrity-resistant design:** "Create an interview guide. For each question, justify why you chose it, what competency it targets, and what poor response would sound like. Identify two questions the AI generated that you rejected and explain why they were inadequate."
- Requires deep understanding, not just production
- Student must demonstrate judgment beyond AI capability
- Reveals whether they understand what they're submitting

---

## Red Flags for AI Misuse (And How to Address Them)

Even with well-designed assignments, some students will try to misuse AI. Here's how to identify and respond:

### Red Flag 1: Sudden Quality Shift

**What you see:** Student whose previous work was weak suddenly submits sophisticated analysis.

**Response approach:**
- **Don't immediately accuse.** There could be legitimate reasons (they got help from writing center, they finally understood the concept, etc.)
- **Ask questions:** "Your analysis has improved significantly. Can you walk me through your thinking process on this particular section?"
- **Request elaboration:** "This point about organisational justice theory is interesting. Can you explain how you see it applying to this specific scenario?"

**If genuine learning:** They can explain their thinking.
**If inappropriate AI use:** They struggle to explain or elaborate.

### Red Flag 2: Work That Doesn't Match Assignment Context

**What you see:** Student used generic AI response that doesn't fit the specific scenario or constraints you provided.

**Example:** Assignment asked for Australian employment law context, student submitted response referencing US legislation.

**Response approach:**
- **Point out the mismatch:** "I notice you've referenced Title VII of the Civil Rights Act, but this assignment requires Australian context. Can you explain how this applies to our scenario?"
- **Provide opportunity to revise:** "I think you may have used a resource that wasn't contextually appropriate. Please resubmit with correct jurisdictional references."

**Teaching moment:** Use this to discuss the importance of contextual verification when using AI tools professionally.

### Red Flag 3: No Evidence of Process in Process-Based Assessment

**What you see:** Student submitted required components but shows no genuine engagement (e.g., self-audit identifies no mistakes, reflection is superficial).

**Response approach:**
- **Return for revision:** "Your self-audit suggests your performance was perfect. Reflective practice requires identifying areas for growth. Please resubmit with honest self-assessment."
- **Offer guidance:** "Everyone makes mistakes in complex HR conversations. Look specifically at moments where the employee seemed frustrated or defensive—what might you have done differently?"

**Teaching moment:** Explain that honest self-assessment is more valuable than false perfection.

### Red Flag 4: Can't Explain or Defend Work in Person

**What you see:** High-quality written submission, but student can't discuss it in office hours or oral follow-up.

**Response approach:**
- **For high-stakes situations:** Schedule a brief oral examination: "I'd like to discuss your assignment. Can you walk me through your main recommendation and why you chose it?"
- **Frame it as learning:** "I was impressed by your analysis. I'd love to hear more about your thinking process."

**If inappropriate use is confirmed:**
- Follow university academic misconduct procedures
- Use it as a teaching moment about professional accountability

---

## Teaching AI Ethics Through Professional Scenarios

One of the most powerful ways to address integrity is to make it a learning objective. Teach students to identify ethical problems with AI use *through discipline-specific scenarios*.

::: {.panel-tabset}

## HR Exercise: The Flawed AI Termination Memo

**Assignment:**

> "Use AI to draft a termination letter for an employee being dismissed for poor performance after a 60-day PIP.
>
> Then conduct an ethical audit:
> - What did the AI include that could create legal risk?
> - What did the AI omit that's legally required?
> - What tone or language choices are problematic?
> - How would you revise this to ensure procedural fairness?
>
> Your grade is based on how thoroughly you identify problems, not on the quality of AI's original output."

**What students learn:**
- AI can confidently generate legally dangerous content
- They must verify and correct AI outputs
- Professional accountability can't be delegated to AI

## Finance Exercise: The Flawed AI Investment Recommendation

**Assignment:**

> "Use AI to recommend an investment portfolio allocation. Then conduct a critical audit:
> - What assumptions did the AI make about risk tolerance and time horizon?
> - What did the AI miss about current market conditions?
> - What tax or regulatory implications are overlooked?
> - How would you revise this recommendation with your professional judgment?
>
> Your grade is based on how thoroughly you identify problems and limitations, not on the quality of AI's original output."

**What students learn:**
- AI can confidently recommend financially risky strategies
- Assumptions must be verified and challenged
- Professional accountability for recommendations can't be delegated

## Supply Chain Exercise: The Flawed AI Supplier Strategy

**Assignment:**

> "Use AI to recommend a supplier consolidation strategy. Then conduct a critical audit:
> - What supply chain risks did the AI overlook?
> - What supplier relationship and quality considerations are missing?
> - What operational constraints wasn't the AI aware of?
> - How would you revise this strategy with on-the-ground knowledge?
>
> Your grade is based on how thoroughly you identify problems and improvements."

**What students learn:**
- AI can oversimplify complex supply chain decisions
- Operational reality must inform strategy
- Professional judgment about supplier relationships is essential

## Marketing Exercise: The Flawed AI Campaign Strategy

**Assignment:**

> "Use AI to generate a campaign strategy for a target market. Then conduct a critical audit:
> - What customer insights did the AI miss or misinterpret?
> - What competitive or market factors aren't addressed?
> - What cultural or regional sensitivities might cause problems?
> - How would you revise this with real market knowledge?
>
> Your grade is based on how thoroughly you identify problems and improvements."

**What students learn:**
- AI can generate culturally insensitive or market-misaligned strategies
- Customer understanding must verify AI outputs
- Professional judgment about market nuance is irreplaceable

## Information Systems Exercise: The Flawed AI System Design

**Assignment:**

> "Use AI to generate system requirements and architecture for a business problem. Then conduct a critical audit:
> - What technical feasibility concerns exist?
> - What security or compliance risks are overlooked?
> - What integration challenges with existing systems aren't considered?
> - How would you revise this design with technical expertise?
>
> Your grade is based on how thoroughly you identify problems and improvements."

**What students learn:**
- AI can generate technically unrealistic designs
- Feasibility and constraints must be verified
- Professional technical judgment is essential

:::

**Common Learning Outcome Across All Disciplines:**
- AI can confidently generate problematic recommendations
- Critical verification and improvement is necessary
- Professional accountability can't be delegated to AI

### Exercise 2: The AI Bias and Fairness Challenge

**Discipline-specific scenarios:**

::: {.panel-tabset}

## HR: The Biased Resume Screening Tool

> "Your company uses an AI resume screening tool. You notice it consistently ranks candidates from certain universities higher and flags career gaps as negative. Three rejected candidates have complained the process seems unfair.
>
> As the HR manager:
> 1. What are the ethical concerns with this AI tool?
> 2. What's your legal risk?
> 3. Who is accountable for the AI's decisions?
> 4. What would you do to address this situation?"

## Finance: The Biased Credit Risk Model

> "Your company uses an AI credit risk model for loan decisions. You discover it systematically rates applicants from certain zip codes as higher risk, even when other factors are equivalent. Multiple applicants have filed complaints.
>
> As the finance manager:
> 1. What are the ethical and legal concerns?
> 2. What's the regulatory risk?
> 3. Who is accountable for discriminatory decisions?
> 4. What would you do to address this?"

## Supply Chain: The Biased Supplier Rating System

> "Your AI supplier rating system consistently rates suppliers from certain regions lower, even when quality metrics are equivalent. Key suppliers have complained and are considering leaving.
>
> As the supply chain manager:
> 1. What are the fairness and business risks?
> 2. What relationship and reputational damage might occur?
> 3. Who is accountable for biased evaluations?
> 4. How would you address this?"

## Marketing: The Biased Customer Segmentation

> "Your AI customer segmentation tool shows significant demographic bias in targeting. Certain groups are consistently excluded from high-value segment classifications. Customer advocacy groups have raised concerns.
>
> As the marketing manager:
> 1. What are the ethical and business risks?
> 2. What's the reputational impact?
> 3. Who is accountable for discriminatory targeting?
> 4. How would you address this?"

:::

**What students learn (across all disciplines):**
- Algorithmic bias is a real professional issue
- Using AI doesn't eliminate human responsibility
- Professionals must advocate for fair processes even when using technology

### Exercise 3: The Over-Reliance Problem

**Discipline-specific scenarios:**

::: {.panel-tabset}

## HR: The Over-Reliance on Turnover Analysis

> "You used AI to analyse exit interview data and generate turnover reduction recommendations. You presented them to senior management and implemented them. Six months later, turnover has increased.
>
> Reflection questions:
> 1. What might the AI have missed in its analysis?
> 2. What was your professional responsibility before presenting AI recommendations?
> 3. How do you explain this outcome to management?
> 4. What does this teach you about using AI in strategic decisions?"

## Finance: The Over-Reliance on Market Forecasting

> "You used AI to forecast market conditions and recommend investment positions. You presented them to the board and implemented them. Three months later, markets moved contrary to the forecast and positions are significantly underwater.
>
> Reflection questions:
> 1. What factors might the AI have missed?
> 2. What was your professional responsibility in validating the forecast?
> 3. How do you explain this to the board?
> 4. What does this teach you about AI-assisted decisions?"

## Supply Chain: The Over-Reliance on Demand Forecasting

> "You used AI to forecast demand and optimize inventory. You implemented major supplier and inventory changes based on this. Demand changed unexpectedly and you now have significant stockouts.
>
> Reflection questions:
> 1. What assumptions might the AI have made incorrectly?
> 2. What was your responsibility to validate the forecast?
> 3. How do you explain this to operations and customers?
> 4. What does this teach you about AI forecasting?"

:::

**What students learn (across all disciplines):**
- AI analysis isn't inherently correct
- Professional judgment can't be outsourced
- They're accountable for recommendations they present, regardless of AI assistance

---

## Responding to Colleague and Administrator Concerns

You may need to justify your approach to colleagues or administrators who are skeptical about AI integration.

### Concern: "This undermines academic standards"

**Response:**

> "Actually, it raises standards. I'm no longer testing whether students can recall information—I'm testing whether they can apply it in realistic, dynamic scenarios. I'm assessing higher-order thinking: critical evaluation, professional judgment, and ethical reasoning. These are harder to demonstrate than memorization."

### Concern: "How do you know they're learning anything?"

**Response:**

> "I assess their process, not just their final product. I can see their thinking in conversation transcripts, in their critiques of AI outputs, and in their reflective analysis. When students can identify what AI got wrong and explain why, they're demonstrating deep understanding."

### Concern: "This doesn't align with university academic integrity policies"

**Response:**

> "University policies typically prohibit *unacknowledged* or *uncritical* use of external sources. My approach makes AI use acknowledged and requires critical evaluation. Students aren't hiding AI use—they're demonstrating competent use. That's consistent with academic integrity principles, just applied to a new tool."

**Supporting evidence:**
- Many universities are updating policies to allow appropriate AI use
- Professional accreditation bodies are recognizing AI literacy as essential
- Employer expectations include ability to use AI tools responsibly

### Concern: "What if other lecturers don't agree?"

**Response:**

> "That's fine—pedagogical approaches can vary across units. I'm being transparent with students about expectations in *my* unit. If other lecturers prohibit AI use, students can follow those different expectations. Professional practice requires adapting to different contexts anyway—this models that."

---

## The Bigger Picture: AI Literacy as Graduate Capability

Position AI literacy as a graduate capability alongside communication, critical thinking, and ethical practice.

### What AI Literacy Means for Business Graduates (All Disciplines)

**Competent graduates across all disciplines should be able to:**

1. **Identify appropriate use cases**
   - When is AI helpful? (data analysis, initial drafts, generating options, research)
   - When is AI risky? (sensitive decisions, final strategic recommendations, high-stakes judgments)
   - When is human judgment essential? (ethical dilemmas, complex stakeholder situations, judgment calls)

2. **Evaluate AI outputs critically**
   - Does this align with legal/regulatory/professional requirements?
   - Is this ethically sound?
   - What assumptions has the AI made?
   - What context or domain expertise is missing?

3. **Maintain accountability**
   - Understanding that using AI doesn't eliminate professional responsibility
   - Knowing when to verify AI recommendations with subject matter experts
   - Documenting decision-making processes and AI role

4. **Recognize bias and limitations**
   - **HR:** Algorithmic bias in recruitment, performance, compensation
   - **Finance:** Bias in risk models, forecasting overconfidence
   - **Supply Chain:** Oversimplification of complex relationships, geopolitical blindspots
   - **Marketing:** Demographic bias in targeting, cultural insensitivity
   - **IT:** Technical feasibility blindness, security oversights
   - **All disciplines:** Over-generalization of complex situations, missing domain context

**This is professional education, not just academic integrity management.**

---

## A Final Ethical Consideration

Here's a question to leave with:

**Is it ethical to graduate professionals who don't know how to use AI responsibly in their field?**

When your graduates enter the workforce across all business disciplines, they will encounter AI in their work:

::: {.panel-tabset}

## HR
- AI-powered recruitment systems making hiring decisions
- Automated performance monitoring and evaluation tools
- AI chatbots handling employee queries
- Algorithmic workforce management systems

## Finance
- AI-powered investment recommendation systems
- Automated risk assessment and credit scoring
- Algorithmic trading and portfolio management
- AI-generated financial forecasts and analysis

## Supply Chain
- AI demand forecasting and inventory optimization
- Algorithmic supplier selection and evaluation
- Automated logistics optimization
- AI-driven supply chain risk assessment

## Marketing
- AI-powered customer segmentation and targeting
- Algorithmic campaign optimization
- AI-generated content and recommendations
- Automated personalisation at scale

## Information Systems
- AI-assisted code generation and testing
- Automated system design and architecture
- AI-powered security threat detection
- Algorithmic project planning and estimation

:::

If they don't understand how to evaluate these tools critically, advocate for responsible use, and identify when human oversight is essential, **they will cause harm**—not through malice, but through incompetence.

Your responsibility as an educator isn't to protect students from AI. It's to prepare them to be ethical, competent professionals in an AI-augmented world.

Teaching them to use AI transparently, critically, and responsibly in your course isn't lowering standards.

**It's fulfilling your educational duty.**

---

## Your Action Step

Before the Appendices, draft your own AI use statement for your next unit outline. Use the framework from this chapter:

1. **When AI use is expected** (specific assignments)
2. **When AI use is permitted** (general study support)
3. **When AI use is not permitted** (exams, specific constraints)
4. **What students must do** (critical engagement, acknowledgment)
5. **Academic integrity expectations** (consequences of misuse)

Write it in your own voice. Make it clear, direct, and positive.

Then review it against this question: **Would a student reading this understand how to use AI appropriately and why it matters for their professional development?**

---

**Next Section Preview:** The Appendices provide ready-to-use resources: a prompt library you can copy and adapt immediately, a one-hour workshop guide for introducing these ideas to colleagues, and a detailed alignment with Curtin University learning outcomes to show how AI integration supports existing educational goals.
