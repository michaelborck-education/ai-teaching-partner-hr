AI Pedagogy for HR Education and Professional Practice
Source guide
This excerpt outlines a pedagogical framework for integrating Artificial Intelligence into Human Resources education, repositioning AI not as a technical gadget but as a powerful, pedagogical partner for both students and lecturers. The core of the strategy focuses on low-tech demonstrations across three key areas to align with university learning outcomes and professional expectations in HR. Firstly, it details prompt engineering for learning, showing how highly specific prompts can generate complex case studies that integrate multiple HR topics like strategic HR planning and psychological theory. Secondly, it addresses assessment support, illustrating how AI can act as a digital teaching assistant to instantly generate grading rubrics and critique student responses, thereby demonstrating technological proficiency in HR management contexts. Finally, the framework stresses the crucial importance of ethical discussion, proposing that students use AI to draft problematic outputs, such as flawed termination memos, to practise identifying and correcting ethical and legislative flaws, ensuring they can apply professional skills in an ethical manner.


This is a vital approach, especially with "smart people" who may be "low-tech," as it reframes AI from a technical novelty to a powerful, pedagogical partner. The demonstration should focus on practical use cases that directly support the learning outcomes of the Bachelor of Commerce (Human Resource Management and Industrial Relations) and the Human Resources Major (MCom).

Curtin University lists **Artificial intelligence** as a component of its values, vision, and strategy, providing strong institutional context for this discussion.

Here are low-tech suggestions for addressing each of your three planned discussion points:

---

## 1. Prompt Engineering for Learning (Curriculum Content Generation)

This section demonstrates how lecturers and students can use AI to generate high-quality, customised content, addressing the undergraduate requirement to **"select and effectively use appropriate technologies relevant to psychological research and practice"**.

### Demonstration Focus: Complex HR Case Studies

Instead of generating simple flashcards, focus on creating a complex **case study** that integrates multiple HR topics taught in the courses, such as **strategic HR planning** and **employment relations**, alongside the psychological concepts of **improving individual and team performance**.

| Action | Low-Tech Prompt Example (Live Input) | HR Relevance & Outcome |
| :--- | :--- | :--- |
| **Step 1: The Basic Prompt (The ‘Ineffective’ Example)** | *Prompt:* "Write a case study about a conflict in a workplace." | Shows generic, low-value output. |
| **Step 2: The Engineered Prompt (The ‘Effective’ Example)** | *Prompt:* **"Act as an expert lecturer in Strategic HR Planning (MCom level). Generate a complex case study (500 words) for a final exam that requires students to apply psychological theory to evidence-based practice and analyse conflict within a high-performing team. Ensure the scenario involves issues related to remuneration and performance and potential breach of relevant legislative and legal rules. Conclude with three essay-style discussion questions requiring critical thinking."** | This high-specificity forces the AI to integrate concepts from the course objectives: **psychological theory**, **evidence-based decisions**, **remuneration and performance**, and **legislative and legal rules**. It results in a resource suitable for **self-directed learning**. |

**Key Takeaway for Lecturers:** The quality of the AI output depends entirely on the specificity of the academic role and required learning outcomes being used in the prompt. This elevates the discussion from "AI writing essays" to "AI assisting instructional design."

---

## 2. Assessment Support (Efficiency and Technological Proficiency)

This section highlights how AI can assist the heavy administrative load of assessment, framing it as a tool that supports the outcome of demonstrating **technological proficiency in HR management contexts**.

### Demonstration Focus: Instant Rubric Generation and Response Critique

| Action | Low-Tech Prompt Example (Live Input) | HR Relevance & Outcome |
| :--- | :--- | :--- |
| **Step 1: Generate the Assessment Tool** | *Prompt:* **"Generate a concise grading rubric (3 criteria, 4 levels) for an undergraduate short-answer question: 'How can a recruitment consultant leverage knowledge of human behaviour to better recruit employees?' The rubric must grade on knowledge integration, critical analysis of problems, and effective communication."** | Directly targets core HR careers (Recruitment consultant) and the need to **apply psychological theory**. Shows AI creating a standardized tool for lecturers. |
| **Step 2: Instant Response Critique** | *Input:* (Paste a mock 150-word student response.) *Prompt:* **"Using the rubric you just generated, evaluate this student's response. Provide a score for each criterion and offer brief feedback on how the student could utilise critical thinking skills to evaluate and integrate information more effectively."** | Demonstrates the ability of the technology to instantly score against predetermined criteria, freeing up lecturer time and supporting the objective of teaching students to **utilise critical thinking skills to evaluate and integrate information**. |

**Key Takeaway for Lecturers:** AI acts as a digital teaching assistant that can rapidly prototype assessment criteria and provide initial, structured feedback, boosting teaching efficacy and demonstrating the kind of technological proficiency expected in modern HR roles.

---

## 3. Ethical Discussion (Professional Conduct and Integrity)

This is crucial because HR professionals are explicitly required to **"apply professional skills in an ethical manner"**. Curtin also stresses the importance of **Academic integrity** in its governance. This segment should show AI's *limitations* and *risks*.

### Demonstration Focus: AI Bias and Ethical Policy Drafting

| Action | Low-Tech Prompt Example (Live Input) | HR Relevance & Outcome |
| :--- | :--- | :--- |
| **Step 1: Generating a Problematic Output** | *Prompt:* **"Draft an initial internal memo (200 words) for management explaining why a recently recruited employee should be terminated after three weeks, based solely on performance data that shows poor initial metrics, without investigating potential underlying causes or giving notice."** | This scenario touches on termination (a high-risk HR area) and a failure to resolve workplace issues fairly. |
| **Step 2: The Critical Review** | *Display the memo.* *Prompt to the audience:* **"In what ways does this AI-generated memo violate the professional expectation to demonstrate understanding and respect for human rights and cultural diversity and apply professional skills in an ethical manner?"**. | This shifts the focus away from "catching plagiarism" to the essential HR skill of **evaluating and applying global HR management practices, recognising cultural differences and ethical considerations**. The AI's failure to incorporate fair process or legal considerations (like knowledge of relevant legislative and legal rules) demonstrates the necessity of human critical oversight. |

**Key Takeaway for Lecturers:** AI doesn't inherently understand ethics or compliance. The use of AI in HR teaching must therefore be mandatory critical practice: students use AI to generate policy drafts or decision outlines, but their grade depends on their ability to identify and correct ethical, legislative, or bias flaws within the AI's output.
